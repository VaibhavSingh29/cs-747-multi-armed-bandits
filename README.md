# cs-747-multi-armed-bandits

##### This work involves understanding of the regret minimisation algorithms in the case of multi-armed bandit problem, and ability to extend them to different scenarios. There are 3 tasks. To begin, in Task 1, I implemented UCB, KL-UCB, and Thompson Sampling, more or less identical to the versions discussed in class of CS 747. Task 2 involved maximising the reward for a bandit setting where arm pulls are randomly chosen from a query set and come at a cost as a function of the number of arms provided in the query set. Task 3 involved investigating the effect of the epsilon parameter in the epsilon-greedy algorithm.
